{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## PROBLEM 1:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "'''\n",
    "Function reads dataset and returns two arrays (X and y) and turns \"?\" into a NaN\n",
    "X = attributes for every patient\n",
    "y = class for each patient\n",
    "'''\n",
    "def import_data(filename=\"./data/arrhythmia.data\"):\n",
    "    X = []\n",
    "    y = []\n",
    "    file = open(filename, 'r')\n",
    "    lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        split_line = line.split(\",\")\n",
    "        X.append(split_line[0:-1]) # List of lists of first 279 attributes\n",
    "        y.append(split_line[-1:][0].split(\"\\n\")[0])  # Remove /n character attached to last element\n",
    "  \n",
    "    # Clean X and y, turn everything to floats and turn \"?\" into NaN\n",
    "    for i, line in enumerate(X):\n",
    "        for j,char in enumerate(line):\n",
    "            if char == \"?\":\n",
    "                X[i][j] = float(\"NaN\")\n",
    "            else:\n",
    "                X[i][j] = float(X[i][j])\n",
    "\n",
    "    for index, line in enumerate(y):\n",
    "        y[index] = float(y[index])\n",
    "\n",
    "    file.close()\n",
    "    return X,y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PROBLEM 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2a)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "'''\n",
    "Computes median of a given list an returns it\n",
    "credit: https://tinyurl.com/3x9hxxtz\n",
    "'''\n",
    "def compute_median(arr):\n",
    "    arr.sort()\n",
    "    mid = len(arr) // 2\n",
    "    res = (arr[mid] + arr[~mid]) / 2\n",
    "    return res\n",
    "\n",
    "'''\n",
    "Convert NaNs in X to median of feature vector (current column of X)\n",
    "\n",
    "Method: Go through each column of X, adding each value to arr, if a NaN value is encountered at any point,\n",
    "        after all (non-nan) data in column is added, go back to each row and replace nan with median\n",
    "'''\n",
    "def impute_missing(X):\n",
    "    # Loop through each column\n",
    "    for col in range(0,len(X[0])):\n",
    "        NaN_exists = False\n",
    "        arr = []\n",
    "        nan_rows = []\n",
    "        # Add all non-nans to array, if NaN is found, NaN_exists = True, save row it was found in nan_rows\n",
    "        for row in range(0,len(X)):\n",
    "            val = X[row][col]\n",
    "            if(val != val):\n",
    "                NaN_exists = True\n",
    "                nan_rows.append(row)\n",
    "            else:\n",
    "                arr.append(val)\n",
    "        # If there was a NaN for the feature, go back to rows and replace with median\n",
    "        if (NaN_exists):\n",
    "            med = compute_median(arr)\n",
    "            for index in nan_rows:\n",
    "                X[index][col] = med\n",
    "\n",
    "\n",
    "        \n",
    "    return X\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2b)\n",
    "\n",
    "Sometimes it is better to use the median over the mean of an attribute due to **outliers** in the feature. Although the mean provides some representation of the data, it can be heavily skewed by values that are much less or greater than the rest of the values in that feature. The median is preferable to accurattely represent where the middle/center of the data lies around."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2c)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "'''\n",
    "Takes in X and y and removes all rows from X that contain a NaN value, removing the\n",
    "corresponding classes as well\n",
    "'''\n",
    "def discard_missing(X,y):\n",
    "    i = 0\n",
    "    while (i<len(X)):\n",
    "        for j, col in enumerate(X[i]):\n",
    "            el = X[i][j]\n",
    "            # If element is a Nan, remove row completely, stay on same row index\n",
    "            if (el != el):\n",
    "                X.pop(i)\n",
    "                y.pop(i)\n",
    "                i -= 1\n",
    "                break;\n",
    "        i += 1\n",
    "    return X,y\n",
    "    \n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3a)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "\n",
    "import numpy as np\n",
    "'''\n",
    "Shuffles rows of data X and corresponding classes of y\n",
    "\n",
    "Method: Create numpy arrays of X, y, generate random permutation of each,\n",
    "        index X,y with same permutation and convert them back to list types\n",
    "        Partial credit to: https://tinyurl.com/4mz22fvv        \n",
    "'''\n",
    "def shuffle_data(X,y):\n",
    "    numpy_X = np.array(X)\n",
    "    numpy_Y = np.array(y)\n",
    "    p = np.random.permutation(len(numpy_X))\n",
    "    X = numpy_X[p].tolist()\n",
    "    y = numpy_Y[p].tolist()\n",
    "    return X,y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3b)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Returns the standard deviation of a list\n",
    "def std_form(arr):\n",
    "    std = 0\n",
    "    N = len(arr)\n",
    "    mean = 0\n",
    "    for el in arr:\n",
    "        mean += el\n",
    "    mean /= N\n",
    "    for el in arr:\n",
    "        std += (el - mean) ** 2\n",
    "    std /= (N-1)\n",
    "    std = std**.5\n",
    "    return std\n",
    "\n",
    "'''\n",
    "Takes in matrix X, and computes the std deviation for each column/feature\n",
    "\n",
    "std = list of std deviations for each feature\n",
    "'''\n",
    "def compute_std(X):\n",
    "    std = []\n",
    "    for col in range(0,len(X[0])):\n",
    "        feature = [i[col] for i in X]\n",
    "        std.append(std_form(feature))\n",
    "\n",
    "    return std"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3c)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "'''\n",
    "Takes in matrix X, and computes the mean for each column/feature\n",
    "\n",
    "mean = list of averages (avg) for each feature\n",
    "'''\n",
    "def compute_mean(X):\n",
    "    mean = []\n",
    "    for col in range(0,len(X[0])):\n",
    "        feature = [i[col] for i in X]\n",
    "        avg = 0\n",
    "        for el in feature:\n",
    "            avg += el\n",
    "        avg /= len(feature)\n",
    "        mean.append(avg)\n",
    "\n",
    "    return mean\n",
    "\n",
    "'''\n",
    "Removes all rows of data that have an attribute that is greater 2*Ïƒ\n",
    "'''\n",
    "def remove_outlier(X,y):\n",
    "    # Get list of standard deviations for each feature\n",
    "    std = compute_std(X)\n",
    "    mean = compute_mean(X)\n",
    "    i = 0\n",
    "    # While the current row index is less than the total number of rows left,\n",
    "    # continue iterating through the columns of current row checking attributes\n",
    "    while (i<len(X)):\n",
    "        for j in range(0,len(X[i])):\n",
    "            el = X[i][j]\n",
    "            # Remove row if attribute more than 2 standard deviations from mean\n",
    "            if (el > mean[j]+(2 * std[j])):\n",
    "                X.pop(i)\n",
    "                y.pop(i)\n",
    "                i -= 1\n",
    "                break;\n",
    "        i += 1\n",
    "    return X,y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3d)\n",
    "\n",
    "Time complexity: O(n*m) where n is the size of X and m is the size of each row of X. compute_std(), compute_mean(), and the rest of standardize_data() all iterate over each element in each row of data once.\n",
    "\n",
    "Space Complexity: O(n+m) where n is the size of X and m is the size of each row of X. To compute the mean and standard deviation, we store arrays of each column (size n) and we store the final arrays of stdevs and means of each column which is size of the number of columns (size m). If we look at only the function itself after getting the std deviation and mean lists, then it would be O(m) only."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "'''\n",
    "Standardizes data in X and returns it back.\n",
    "'''\n",
    "def standardize_data(X):\n",
    "    std = compute_std(X)\n",
    "    mean = compute_mean(X)\n",
    "    N = len(X[0]) \n",
    "    for i in range(0,len(X)):\n",
    "        for j in range(0,N):\n",
    "            # Standardize where stdev is 0 by replacing value with 0\n",
    "            if (std[j]==0):\n",
    "                X[i][j] = 0\n",
    "            else:\n",
    "                X[i][j] -= mean[j]\n",
    "                X[i][j] /= std[j]\n",
    "    return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Main function for problems 1-3:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# X,y = import_data(\"./data/arrhythmia.data\")\n",
    "# X = impute_missing(X)\n",
    "# X,y = discard_missing(X,y)\n",
    "# X = standardize_data(X)\n",
    "# # # X,y = shuffle_data(X,y)\n",
    "# # std = compute_std(X)\n",
    "# X, y = remove_outlier(X,y)\n",
    "# X = standardize_data(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "'''\n",
    "Takes in titanic dataset from \"./data/train.csv\" and extracts and cleans data into matrix X and class y\n",
    "'''\n",
    "\n",
    "def import_titanic_dataset(filename=\"./data/train.csv\"):\n",
    "    X = []\n",
    "    y = []\n",
    "    f = open(filename, 'r')\n",
    "    lines = f.readlines()\n",
    "    # Column j=1 is the class so don't include it in X\n",
    "    # Column j=3 is a comma separated name, so include both parts of split back together\n",
    "    for line in lines[1:]:\n",
    "        split_line = line.split(',')\n",
    "        parsed_line = []\n",
    "        # Append columns 0, 2\n",
    "        parsed_line.append(split_line[0])\n",
    "        parsed_line.append(split_line[2])\n",
    "        # Recombine split name and append\n",
    "        name = split_line[3] + \", \" + split_line[4]\n",
    "        parsed_line.append(name)\n",
    "        # Append the rest of the columns\n",
    "        i = 5\n",
    "        while(i < len(split_line)):\n",
    "            # Convert sex (i=5) into 0 if female, 1 if male\n",
    "            if (i==5):\n",
    "                if (split_line[i] == \"\"):\n",
    "                    sex = float(\"NaN\")\n",
    "                else:\n",
    "                    sex = 0 if (split_line[i] == \"female\") else 1\n",
    "                parsed_line.append(sex)\n",
    "                i+=1\n",
    "                continue;\n",
    "            # Convert embarked (j = last column) such that C=0,Q=1, S=2 -- NaN if blank\n",
    "            if (i==len(split_line)-1):\n",
    "                embarked = split_line[i].split(\"\\n\")[0]  # Remove /n character attached to last element\n",
    "                if (embarked == \"C\"):\n",
    "                    embarked = 0\n",
    "                elif (embarked == \"Q\"):\n",
    "                    embarked = 1\n",
    "                elif (embarked == \"S\"):\n",
    "                    embarked = 2\n",
    "                else:\n",
    "                    embarked = float(\"NaN\")\n",
    "                parsed_line.append(embarked)\n",
    "                i+=1\n",
    "                continue;\n",
    "            parsed_line.append(split_line[i])\n",
    "            i += 1\n",
    "        X.append(parsed_line)\n",
    "        \n",
    "    # Take survived column of each line and add it to y (converted to float)\n",
    "    for line in lines[1:]:\n",
    "        y.append(float(line.split(\",\")[1]))\n",
    "    \n",
    "    #Replace missing entries with NaNs\n",
    "    for i in range(0,len(X)):\n",
    "        for j in range(0,len(X[i])):\n",
    "            if X[i][j] == \"\":\n",
    "                X[i][j] = float(\"NaN\")\n",
    "\n",
    "    f.close()\n",
    "    return X,y\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "main function for problem 4:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "X,y = import_titanic_dataset(\"data/train.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 5"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5a)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "source": [
    "import numpy as np\n",
    "'''\n",
    "Takes in data X, labels y, and decimal t_f which indicates\n",
    "how much of the dataset should be randomly split into test set,\n",
    "with the remaining going to a training set\n",
    "\n",
    "Method: shuffles X and y randomly, then simply takes splits the first t_f into test and other t_f into train\n",
    "\n",
    "'''\n",
    "def train_test_split(X, y, t_f):\n",
    "    X_train, y_train, X_test, y_test = [], [], [], []\n",
    "    # Shuffle the data\n",
    "    X, y = shuffle_data(X,y)\n",
    "    assert(len(X) == len(y))\n",
    "    # Get index where to split the data based on percentage of total number of valuess\n",
    "    part_index = int(len(X)*t_f)\n",
    "    # Partition data around part_index\n",
    "    X_test = X[0:part_index]\n",
    "    y_test = y[0:part_index]\n",
    "    X_train = X[part_index:]\n",
    "    y_train = y[part_index:]\n",
    "    return X_train, y_train, X_test, y_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5b)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "source": [
    "'''\n",
    "Splits the dataset into 3 sections, test, training, and cross validation sets and returns them\n",
    "'''\n",
    "def train_test_CV_split(X, y, t_f, cv_f):\n",
    "    X_train, y_train, X_test, y_test, X_cv, y_cv = [], [], [], [], [], []\n",
    "    # Shuffle the data\n",
    "    X, y = shuffle_data(X,y)\n",
    "    assert(len(X) == len(y))\n",
    "    \n",
    "    # Assign index based on first split around test set\n",
    "    part_index_t_f = int(len(X)*t_f)\n",
    "    # Assign second partition index from the previous index\n",
    "    part_index_cv_f = int(len(X)*cv_f)+part_index_t_f\n",
    "    '''Partition data from beginning to part_index_t_f to go to testing set\n",
    "    then put from part_index_t_f to part_index_cv_f to go to cross validation set\n",
    "    then put the rest into the training set''' \n",
    "    X_test = X[0:part_index_t_f]\n",
    "    y_test = y[0:part_index_t_f]\n",
    "    X_cv = X[part_index_t_f:part_index_cv_f]\n",
    "    y_cv = y[part_index_t_f:part_index_cv_f]\n",
    "    X_train = X[part_index_cv_f:]\n",
    "    y_train = y[part_index_cv_f:]\n",
    "    return X_train, y_train, X_test, y_test, X_cv, y_cv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "main function for problem 5 (keep X and y assignments commented to use previous X and y matrices)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "source": [
    "# X = [[1,2],[3,4],[5,6],[7,8],[9,10]]\n",
    "# y = [1,2,3,4,5]\n",
    "# t_f = 2/10\n",
    "# X_train, y_train, X_test, y_test = train_test_split(X,y,t_f)\n",
    "# cv_f = 4/10\n",
    "# X_train, y_train, X_test, y_test, X_cv, y_cv = train_test_CV_split(X,y,t_f,cv_f)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "55eee06a2bbca1324852114ff98b2734a2f644c18cde0f66557ad155195a4f3b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}